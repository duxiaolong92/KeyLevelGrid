"""
MTF æ°´ä½ç”Ÿæˆå¼•æ“ (LEVEL_GENERATION.md v3.2.5)

ä¸»å…¥å£ç±»ï¼Œé›†æˆæ‰€æœ‰å­æ¨¡å—:
- FractalExtractor: åˆ†å½¢ç‚¹æå– (å››å±‚çº§)
- VPVRAnalyzer: æˆäº¤é‡åˆ†å¸ƒåˆ†æ
- PsychologyMatcher: å¿ƒç†ä½åŒ¹é…
- LevelScorer: è¯„åˆ†è®¡ç®— (V3.2.5 æƒé‡)
- MTFMerger: å¤šæ¡†æ¶èåˆ
- ATRGapAuditor: ATR ç©ºé—´ç¡¬çº¦æŸ (V3.2.5 æ ¸å¿ƒ)

æ ¸å¿ƒæµç¨‹:
1. ä»å››å±‚çº§ K çº¿æ•°æ®æå–åˆ†å½¢ç‚¹
2. åˆå¹¶ç›¸è¿‘ä»·ä½ï¼Œè¯†åˆ«å…±æŒ¯æ°´ä½
3. ATR ç©ºé—´å®¡è®¡ (å¯†åº¦è£å‰ª + ç¨€ç–è¡¥å…¨)
4. å¯¹é½å¿ƒç†ä½ (æ–æ³¢é‚£å¥‘/æ•´æ•°ä½)
5. è®¡ç®—ç»¼åˆè¯„åˆ†
6. æŒ‰è¯„åˆ†ç­›é€‰æœ€ç»ˆæ°´ä½
"""

import logging
from typing import List, Dict, Optional, Tuple

from key_level_grid.core.scoring import (
    LevelScore,
    FractalPoint,
    VPVRData,
    MTFLevelCandidate,
    TrendState,
)
from key_level_grid.core.triggers import (
    ManualBoundary,
    ATRConfig,
)
from key_level_grid.analysis.fractal import (
    FractalExtractor,
    get_anchor_price,
    get_anchor_by_layer,
)
from key_level_grid.analysis.vpvr import VPVRAnalyzer
from key_level_grid.analysis.psychology import PsychologyMatcher
from key_level_grid.analysis.scorer import LevelScorer, determine_trend
from key_level_grid.analysis.mtf_merger import MTFMerger, select_top_levels
from key_level_grid.analysis.atr_gap_auditor import ATRGapAuditor, AuditResult


logger = logging.getLogger(__name__)


class LevelCalculator:
    """
    MTF æ°´ä½ç”Ÿæˆå¼•æ“ (V3.2.5)
    
    æ ¸å¿ƒæ¨¡å—ï¼Œè´Ÿè´£:
    - ä»å››å±‚çº§æ—¶é—´æ¡†æ¶ K çº¿æ•°æ®ç”Ÿæˆç›®æ ‡æ°´ä½
    - æ‰§è¡Œ ATR ç©ºé—´ç¡¬çº¦æŸå®¡è®¡
    - è®¡ç®—æ¯ä¸ªæ°´ä½çš„ç»¼åˆè¯„åˆ†
    - æ”¯æŒæ‰‹åŠ¨è¾¹ç•Œå’Œè·ç¦»è¿‡æ»¤
    """
    
    def __init__(self, config: Optional[Dict] = None):
        """
        åˆå§‹åŒ–æ°´ä½è®¡ç®—å™¨
        
        Args:
            config: é…ç½®å­—å…¸ (ä» config.yaml åŠ è½½)
        """
        self.config = config or {}
        level_gen_config = self.config.get("level_generation", {})
        
        # åˆå§‹åŒ–å­æ¨¡å—
        self.fractal_extractor = FractalExtractor(
            fibonacci_lookback=level_gen_config.get("fibonacci_lookback"),
            config=level_gen_config,
        )
        
        self.vpvr_analyzer = VPVRAnalyzer(
            config=level_gen_config,
        )
        
        self.psychology_matcher = PsychologyMatcher(
            config=level_gen_config,
        )
        
        self.scorer = LevelScorer(config=level_gen_config)
        
        self.mtf_merger = MTFMerger(
            merge_tolerance=float(
                self.config.get("resistance", {}).get("merge_tolerance", 0.005)
            ),
            timeframe_priority=self._get_timeframe_priority(level_gen_config),
            config=level_gen_config,
        )
        
        # V3.2.5: ATR ç©ºé—´å®¡è®¡å™¨
        atr_config_dict = level_gen_config.get("atr_constraint", {})
        self.atr_config = ATRConfig.from_dict(atr_config_dict)
        self.atr_auditor = ATRGapAuditor(config=self.atr_config)
        
        # è·ç¦»è¿‡æ»¤é…ç½®
        resistance_config = self.config.get("resistance", {})
        self.min_distance_pct = float(resistance_config.get("min_distance_pct", 0.001))
        self.max_distance_pct = float(resistance_config.get("max_distance_pct", 0.30))
        
        # æ‰‹åŠ¨è¾¹ç•Œ
        boundary_config = level_gen_config.get("manual_boundary", {})
        self.manual_boundary = ManualBoundary(
            enabled=boundary_config.get("enabled", False),
            upper_price=boundary_config.get("upper_price"),
            lower_price=boundary_config.get("lower_price"),
            mode=boundary_config.get("mode", "strict"),
            buffer_pct=float(boundary_config.get("buffer_pct", 0.0)),
        )
        
        # è¯„åˆ†é˜ˆå€¼
        scoring_config = level_gen_config.get("scoring", {})
        self.min_score_threshold = float(scoring_config.get("min_score_threshold", 30))
        self.display_score_threshold = float(scoring_config.get("display_score_threshold", 0))
        
        # ç¼“å­˜æœ€è¿‘çš„å®¡è®¡ç»“æœ
        self._last_audit_result: Optional[AuditResult] = None
    
    def _get_timeframe_priority(self, config: Dict) -> List[str]:
        """è·å–æ—¶é—´æ¡†æ¶ä¼˜å…ˆçº§åˆ—è¡¨"""
        tf_config = config.get("timeframes", {})
        
        priority = []
        
        # L1 æˆ˜ç•¥å±‚
        l1 = tf_config.get("l1_strategy", {})
        if l1.get("enabled", True):
            priority.append(l1.get("interval", "1w"))
        
        # L2 éª¨æ¶å±‚
        l2 = tf_config.get("l2_skeleton", {})
        priority.append(l2.get("interval", "1d"))
        
        # L3 ä¸­ç»§å±‚
        l3 = tf_config.get("l3_relay", {})
        priority.append(l3.get("interval", "4h"))
        
        # L4 æˆ˜æœ¯å±‚
        l4 = tf_config.get("l4_tactical", {})
        if l4.get("enabled", True):
            priority.append(l4.get("interval", "15m"))
        
        return priority or ["1d", "4h", "15m"]
    
    def generate_target_levels(
        self,
        klines_by_tf: Dict[str, List[Dict]],
        current_price: float,
        role: str = "support",
        max_levels: int = 10,
        use_atr_audit: bool = True,
    ) -> Optional[List[Tuple[float, LevelScore]]]:
        """
        ç”Ÿæˆç›®æ ‡æ°´ä½åˆ—è¡¨ (V3.2.5)
        
        Args:
            klines_by_tf: å¤šæ—¶é—´æ¡†æ¶ K çº¿æ•°æ® {"1w": [...], "1d": [...], "4h": [...], "15m": [...]}
            current_price: å½“å‰ä»·æ ¼
            role: "support" | "resistance"
            max_levels: æœ€å¤§æ°´ä½æ•°
            use_atr_audit: æ˜¯å¦å¯ç”¨ ATR ç©ºé—´å®¡è®¡
        
        Returns:
            [(price, LevelScore), ...] æŒ‰ä»·æ ¼é™åºæ’åˆ—
            å¦‚æœæ•°æ®ä¸è¶³æˆ–å‡ºé”™ï¼Œè¿”å› None
        """
        # éªŒè¯è¾“å…¥
        if not klines_by_tf or current_price <= 0:
            logger.warning("Invalid input: empty klines or invalid price")
            return None
        
        # 1. æå–åˆ†å½¢ç‚¹ (å››å±‚çº§)
        fractals_by_tf = self.fractal_extractor.extract_from_mtf(klines_by_tf)
        
        total_fractals = sum(len(f) for f in fractals_by_tf.values())
        if total_fractals == 0:
            logger.warning("No fractals extracted from klines")
            return None
        
        # è¯¦ç»†æ—¥å¿—ï¼šåˆ†å½¢ç‚¹ç»Ÿè®¡
        for tf, fractals in fractals_by_tf.items():
            highs = [f for f in fractals if f.type == "HIGH"]
            lows = [f for f in fractals if f.type == "LOW"]
            logger.debug(f"[{tf}] åˆ†å½¢ç‚¹: {len(fractals)} ä¸ª (HIGH={len(highs)}, LOW={len(lows)})")
            if role == "resistance" and highs:
                high_prices = [f.price for f in highs[:5]]
                logger.debug(f"[{tf}] å‰5ä¸ª HIGH ä»·æ ¼: {high_prices}")
        
        logger.debug(f"Extracted {total_fractals} fractals from MTF data")
        
        # 2. åˆå¹¶å¤šæ¡†æ¶åˆ†å½¢ç‚¹
        candidates = self.mtf_merger.merge_fractals(fractals_by_tf)
        logger.debug(f"åˆå¹¶åå€™é€‰æ•°: {len(candidates)}")
        
        # 3. æŒ‰è§’è‰²è¿‡æ»¤ (æ”¯æ’‘ä½å–ä½ç‚¹ï¼Œé˜»åŠ›ä½å–é«˜ç‚¹)
        if role == "support":
            candidates = self.mtf_merger.filter_by_type(candidates, "LOW")
            # æ”¯æ’‘ä½åªå–ä½äºå½“å‰ä»·çš„
            candidates = [c for c in candidates if c.merged_price < current_price]
        else:
            before_type_filter = len(candidates)
            candidates = self.mtf_merger.filter_by_type(candidates, "HIGH")
            logger.debug(f"ç±»å‹è¿‡æ»¤ (HIGH): {before_type_filter} -> {len(candidates)}")
            
            # é˜»åŠ›ä½åªå–é«˜äºå½“å‰ä»·çš„
            before_price_filter = len(candidates)
            candidates = [c for c in candidates if c.merged_price > current_price]
            logger.debug(f"ä»·æ ¼è¿‡æ»¤ (>{current_price:.2f}): {before_price_filter} -> {len(candidates)}")
            
            if before_price_filter > 0 and len(candidates) == 0:
                # æ‰€æœ‰ HIGH éƒ½ä½äºå½“å‰ä»·
                all_high_prices = [c.merged_price for c in self.mtf_merger.filter_by_type(
                    self.mtf_merger.merge_fractals(fractals_by_tf), "HIGH"
                )]
                if all_high_prices:
                    logger.warning(
                        f"æ‰€æœ‰ HIGH åˆ†å½¢ç‚¹ ({len(all_high_prices)} ä¸ª) éƒ½ä½äºå½“å‰ä»· {current_price:.2f}, "
                        f"æœ€é«˜: {max(all_high_prices):.2f}"
                    )
        
        # 4. è·ç¦»è¿‡æ»¤
        before_distance = len(candidates)
        candidates = self.mtf_merger.filter_by_distance(
            candidates,
            current_price,
            self.min_distance_pct,
            self.max_distance_pct,
        )
        logger.debug(f"è·ç¦»è¿‡æ»¤ ({self.min_distance_pct*100:.1f}%-{self.max_distance_pct*100:.1f}%): {before_distance} -> {len(candidates)}")
        
        if not candidates:
            logger.warning(f"No candidates after filtering for role={role}")
            
            # V3.2.5: é˜»åŠ›ä½å¤‡é€‰æ–¹æ¡ˆ - ä½¿ç”¨å¿ƒç†ä½
            if role == "resistance":
                fallback_levels = self._generate_fallback_resistance(
                    klines_by_tf, current_price, max_levels
                )
                if fallback_levels:
                    logger.info(f"[Fallback] ä½¿ç”¨å¿ƒç†ä½ç”Ÿæˆ {len(fallback_levels)} ä¸ªé˜»åŠ›ä½")
                    return fallback_levels
            
            return None
        
        logger.debug(f"After filtering: {len(candidates)} candidates")
        
        # 5. V3.2.5: ATR ç©ºé—´å®¡è®¡
        if use_atr_audit and self.atr_config.enabled:
            # è®¾ç½® VPVR æ•°æ®å’Œæˆ˜æœ¯æ± 
            main_tf = self._get_main_timeframe(klines_by_tf)
            vpvr = self.vpvr_analyzer.analyze(klines_by_tf.get(main_tf, []))
            self.atr_auditor.set_vpvr_data(vpvr)
            
            # è®¾ç½® L4 æˆ˜æœ¯æ± 
            tactical_tf = self._get_tactical_timeframe(klines_by_tf)
            if tactical_tf and tactical_tf in fractals_by_tf:
                self.atr_auditor.set_tactical_pool(fractals_by_tf[tactical_tf])
            
            # è®¡ç®— ATR
            atr_tf = self.atr_config.atr_timeframe
            atr_klines = klines_by_tf.get(atr_tf, klines_by_tf.get(main_tf, []))
            atr = self.atr_auditor.calculate_atr(atr_klines)
            
            # æ‰§è¡Œå®¡è®¡
            candidates, audit_result = self.atr_auditor.audit(candidates, atr)
            self._last_audit_result = audit_result
            
            # âš ï¸ é‡è¦: ATR è¡¥å…¨å¯èƒ½äº§ç”Ÿä¸ç¬¦åˆæ–¹å‘çš„æ°´ä½ï¼Œéœ€è¦å†æ¬¡è¿‡æ»¤
            before_refilter = len(candidates)
            if role == "support":
                candidates = [c for c in candidates if c.merged_price < current_price]
            else:
                candidates = [c for c in candidates if c.merged_price > current_price]
            
            if before_refilter != len(candidates):
                logger.debug(f"ATR è¡¥å…¨åæ–¹å‘è¿‡æ»¤: {before_refilter} -> {len(candidates)}")
            
            # ğŸ†• æ£€æŸ¥å½“å‰ä»·æ ¼åˆ°æœ€è¿‘æ°´ä½ä¹‹é—´æ˜¯å¦æœ‰å¤§ç©ºéš™ï¼Œéœ€è¦è¡¥å…¨
            if candidates:
                max_gap = self.atr_config.gap_max_atr_ratio * atr
                
                if role == "resistance":
                    # é˜»åŠ›ä½ï¼šæ£€æŸ¥å½“å‰ä»·æ ¼åˆ°æœ€ä½é˜»åŠ›ä½çš„è·ç¦»
                    nearest = min(c.merged_price for c in candidates)
                    gap = nearest - current_price
                    
                    if gap > max_gap:
                        logger.info(f"é˜»åŠ›ä½ç©ºéš™è¿‡å¤§: {current_price:.2f} -> {nearest:.2f} (gap={gap:.2f}, max={max_gap:.2f})")
                        # åœ¨å½“å‰ä»·æ ¼å’Œæœ€è¿‘é˜»åŠ›ä½ä¹‹é—´è¡¥å…¨
                        filled = self._fill_gap_to_price(current_price, nearest, atr, "resistance")
                        if filled:
                            candidates.extend(filled)
                            candidates = sorted(candidates, key=lambda c: c.merged_price, reverse=True)
                            logger.info(f"è¡¥å…¨äº† {len(filled)} ä¸ªè¿‘è·ç¦»é˜»åŠ›ä½")
                else:
                    # æ”¯æ’‘ä½ï¼šæ£€æŸ¥æœ€é«˜æ”¯æ’‘ä½åˆ°å½“å‰ä»·æ ¼çš„è·ç¦»
                    nearest = max(c.merged_price for c in candidates)
                    gap = current_price - nearest
                    
                    if gap > max_gap:
                        logger.info(f"æ”¯æ’‘ä½ç©ºéš™è¿‡å¤§: {nearest:.2f} -> {current_price:.2f} (gap={gap:.2f}, max={max_gap:.2f})")
                        # åœ¨æœ€è¿‘æ”¯æ’‘ä½å’Œå½“å‰ä»·æ ¼ä¹‹é—´è¡¥å…¨
                        filled = self._fill_gap_to_price(nearest, current_price, atr, "support")
                        if filled:
                            candidates.extend(filled)
                            candidates = sorted(candidates, key=lambda c: c.merged_price, reverse=True)
                            logger.info(f"è¡¥å…¨äº† {len(filled)} ä¸ªè¿‘è·ç¦»æ”¯æ’‘ä½")
            
            if not candidates:
                logger.warning("No candidates after ATR audit")
                return None
        else:
            # ä¸ä½¿ç”¨ ATR å®¡è®¡æ—¶ï¼Œä»éœ€è·å– VPVR
            main_tf = self._get_main_timeframe(klines_by_tf)
            vpvr = self.vpvr_analyzer.analyze(klines_by_tf.get(main_tf, []))
        
        # 6. è·å–å¿ƒç†ä½
        psychology_levels = self.psychology_matcher.find_all_psychology_levels(
            klines_by_tf.get(main_tf, [])
        )
        
        # 7. åˆ¤æ–­è¶‹åŠ¿
        trend_state = determine_trend(klines_by_tf.get(main_tf, []))
        logger.debug(f"Trend state: {trend_state}")
        
        # 8. è®¡ç®—è¯„åˆ†
        scores: Dict[float, LevelScore] = {}
        
        for candidate in candidates:
            # å°è¯•å¿ƒç†ä½åŒ¹é… (ä»…ç”¨äºè¯„åˆ†åŠ æˆï¼Œä¸å¸é™„ä»·æ ¼)
            snapped_price, psy_match = self.psychology_matcher.snap_to_psychology(
                candidate.merged_price,
                psychology_levels,
            )
            
            # æ³¨æ„: ä¸å†è¦†ç›– candidate.merged_price
            # ä¿ç•™åŸå§‹åˆ†å½¢ä»·æ ¼ï¼Œä»…åœ¨è¯„åˆ†æ—¶ç»™äºˆå¿ƒç†ä½åŠ æˆ
            
            # è®¡ç®—è¯„åˆ†
            score = self.scorer.calculate_score(
                candidate=candidate,
                vpvr=vpvr,
                trend_state=trend_state,
                role=role,
                psychology_anchor=snapped_price if psy_match else None,
            )
            
            # V3.2.5: å¦‚æœæ˜¯è¡¥å…¨æ°´ä½ï¼Œä½¿ç”¨è¡¥å…¨æ—¶çš„è¯„åˆ†
            if hasattr(candidate, 'fill_type') and candidate.fill_type:
                if hasattr(candidate, 'score') and candidate.score:
                    score.final_score = max(score.final_score, candidate.score)
            
            scores[candidate.merged_price] = score
        
        # 9. è¿‡æ»¤ä½è¯„åˆ†æ°´ä½
        filtered_candidates = []
        for candidate in candidates:
            price = candidate.merged_price
            if price in scores:
                score = scores[price]
                if score.final_score >= self.min_score_threshold:
                    filtered_candidates.append(candidate)
                else:
                    logger.debug(f"Filtered level {price:.2f} with score {score.final_score:.1f} < {self.min_score_threshold}")
        
        if not filtered_candidates:
            logger.warning(f"No candidates above min_score_threshold={self.min_score_threshold}")
            return None
        
        # 10. åº”ç”¨æ‰‹åŠ¨è¾¹ç•Œè¿‡æ»¤
        if self.manual_boundary.enabled:
            prices_before = [c.merged_price for c in filtered_candidates]
            prices_after = self.manual_boundary.filter_levels(prices_before)
            
            # æ›´æ–°å€™é€‰åˆ—è¡¨
            filtered_candidates = [
                c for c in filtered_candidates 
                if c.merged_price in prices_after
            ]
            
            if not filtered_candidates:
                logger.warning("No candidates after manual boundary filter")
                return None
            
            logger.debug(f"After boundary filter: {len(prices_before)} -> {len(filtered_candidates)} levels")
        
        # 11. é€‰æ‹©è¯„åˆ†æœ€é«˜çš„æ°´ä½
        top_levels = select_top_levels(filtered_candidates, scores, max_levels)
        
        # 12. æŒ‰ä»·æ ¼é™åºæ’åˆ—
        top_levels.sort(key=lambda x: x[0], reverse=True)
        
        logger.info(f"Generated {len(top_levels)} target levels for role={role}")
        return top_levels
    
    def _get_main_timeframe(self, klines_by_tf: Dict[str, List[Dict]]) -> str:
        """è·å–ä¸»æ—¶é—´æ¡†æ¶ (L3 ä¸­ç»§å±‚ 4h)"""
        if not klines_by_tf:
            return "4h"
        
        # ä¼˜å…ˆä½¿ç”¨ 4h (L3 ä¸­ç»§å±‚)
        if "4h" in klines_by_tf:
            return "4h"
        
        # å¦åˆ™ä½¿ç”¨æ•°æ®æœ€å¤šçš„
        return max(klines_by_tf, key=lambda k: len(klines_by_tf[k]))
    
    def _get_tactical_timeframe(self, klines_by_tf: Dict[str, List[Dict]]) -> Optional[str]:
        """è·å–æˆ˜æœ¯æ—¶é—´æ¡†æ¶ (L4 15m)"""
        if "15m" in klines_by_tf:
            return "15m"
        return None
    
    def _create_default_score(self, price: float, role: str) -> LevelScore:
        """ä¸ºæ‰‹åŠ¨è¾¹ç•Œåˆ›å»ºé»˜è®¤è¯„åˆ†"""
        return LevelScore(
            base_score=30,
            source_timeframes=["manual"],
            source_periods=[],
            final_score=30,
        )
    
    def get_anchor_price(self, klines: List[Dict], lookback: int = 55) -> Optional[float]:
        """
        è·å–é”šç‚¹ä»·æ ¼
        
        Args:
            klines: K çº¿æ•°æ®
            lookback: å›æº¯å‘¨æœŸ
        
        Returns:
            é”šç‚¹ä»·æ ¼
        """
        return get_anchor_price(klines, lookback)
    
    def get_anchor_by_layer(
        self,
        klines_by_layer: Dict[str, List[Dict]],
        anchor_layer: str = "l2",
        anchor_period: int = 55,
    ) -> Optional[float]:
        """
        æŒ‰å±‚çº§è·å–é”šç‚¹ä»·æ ¼ (V3.2.5)
        
        Args:
            klines_by_layer: {"l1": [...], "l2": [...], ...}
            anchor_layer: é”šç‚¹å±‚çº§ (é»˜è®¤ "l2")
            anchor_period: é”šç‚¹å›æº¯å‘¨æœŸ (é»˜è®¤ 55)
        
        Returns:
            é”šç‚¹ä»·æ ¼
        """
        return get_anchor_by_layer(klines_by_layer, anchor_layer, anchor_period)
    
    def get_last_audit_result(self) -> Optional[AuditResult]:
        """è·å–æœ€è¿‘ä¸€æ¬¡ ATR å®¡è®¡ç»“æœ"""
        return self._last_audit_result
    
    def refresh_scores(
        self,
        existing_levels: List[Tuple[float, LevelScore]],
        klines_by_tf: Dict[str, List[Dict]],
        current_price: float,
        role: str = "support",
    ) -> List[Tuple[float, LevelScore]]:
        """
        åˆ·æ–°ç°æœ‰æ°´ä½çš„è¯„åˆ† (ä¸æ”¹å˜æ°´ä½ä»·æ ¼)
        
        ç”¨äº 15m æˆ˜æœ¯å±‚æ›´æ–°ï¼Œåªæ›´æ–°è¯„åˆ†ä¸è§¦å‘é‡æ„ã€‚
        V3.2.5: ä¸¥ç¦ä¿®æ”¹æŒ‚å•ä»·æ ¼
        
        Args:
            existing_levels: ç°æœ‰æ°´ä½åˆ—è¡¨
            klines_by_tf: æœ€æ–° K çº¿æ•°æ®
            current_price: å½“å‰ä»·æ ¼
            role: "support" | "resistance"
        
        Returns:
            æ›´æ–°è¯„åˆ†åçš„æ°´ä½åˆ—è¡¨
        """
        if not existing_levels:
            return []
        
        # é‡æ–°æå–åˆ†å½¢ç‚¹
        fractals_by_tf = self.fractal_extractor.extract_from_mtf(klines_by_tf)
        
        # VPVR åˆ†æ
        main_tf = self._get_main_timeframe(klines_by_tf)
        vpvr = self.vpvr_analyzer.analyze(klines_by_tf.get(main_tf, []))
        
        # åˆ¤æ–­è¶‹åŠ¿
        trend_state = determine_trend(klines_by_tf.get(main_tf, []))
        
        # é‡æ–°è®¡ç®—è¯„åˆ†
        result = []
        
        for price, old_score in existing_levels:
            # æ‰¾åˆ°æœ€è¿‘çš„åˆ†å½¢ç‚¹
            candidate = self._find_nearest_candidate(
                price, fractals_by_tf, old_score.source_timeframes
            )
            
            if candidate:
                new_score = self.scorer.calculate_score(
                    candidate=candidate,
                    vpvr=vpvr,
                    trend_state=trend_state,
                    role=role,
                    psychology_anchor=old_score.psychology_anchor,
                )
            else:
                # ä¿æŒæ—§è¯„åˆ†ä½†æ›´æ–°è¶‹åŠ¿ç³»æ•°
                new_score = old_score
                new_score.trend_state = trend_state
            
            result.append((price, new_score))
        
        return result
    
    def _find_nearest_candidate(
        self,
        price: float,
        fractals_by_tf: Dict[str, List[FractalPoint]],
        source_timeframes: List[str],
        tolerance: float = 0.01,
    ) -> Optional[MTFLevelCandidate]:
        """æ‰¾åˆ°æœ€è¿‘çš„åˆ†å½¢ç‚¹å€™é€‰"""
        all_fractals = []
        for tf in source_timeframes:
            if tf in fractals_by_tf:
                all_fractals.extend(fractals_by_tf[tf])
        
        if not all_fractals:
            return None
        
        # æ‰¾æœ€è¿‘çš„åˆ†å½¢ç‚¹
        nearest = min(
            all_fractals,
            key=lambda f: abs(f.price - price) / price,
        )
        
        if abs(nearest.price - price) / price > tolerance:
            return None
        
        return MTFLevelCandidate(
            price=price,
            source_fractals=[nearest],
            source_timeframes=[nearest.timeframe],
            merged_price=price,
        )
    
    def _fill_gap_to_price(
        self,
        lower: float,
        upper: float,
        atr: float,
        role: str,
    ) -> List[MTFLevelCandidate]:
        """
        åœ¨å½“å‰ä»·æ ¼å’Œæœ€è¿‘æ°´ä½ä¹‹é—´è¡¥å…¨
        
        Args:
            lower: åŒºé—´ä¸‹ç•Œ
            upper: åŒºé—´ä¸Šç•Œ
            atr: ATR å€¼
            role: "support" | "resistance"
        
        Returns:
            è¡¥å…¨çš„å€™é€‰æ°´ä½åˆ—è¡¨
        """
        from key_level_grid.core.scoring import MTFLevelCandidate
        
        filled = []
        gap = upper - lower
        max_gap = self.atr_config.gap_max_atr_ratio * atr
        
        if gap <= max_gap:
            return filled
        
        # è®¡ç®—éœ€è¦å¤šå°‘ä¸ªè¡¥å…¨ç‚¹
        # ä½¿ç”¨ 0.618 é»„é‡‘åˆ†å‰²é€’å½’è¡¥å…¨
        fib_ratio = self.atr_config.fibonacci_fill_ratio
        fill_score = self.atr_config.fibonacci_fill_score
        
        def recursive_fill(lo: float, hi: float, depth: int = 0):
            if depth > 10:  # é˜²æ­¢æ— é™é€’å½’
                return
            
            g = hi - lo
            if g <= max_gap:
                return
            
            # åœ¨ 0.618 ä½ç½®æ’å…¥
            if role == "resistance":
                # é˜»åŠ›ä½ï¼šä»ä½å‘é«˜ï¼Œåœ¨ lo + 0.618 * gap å¤„æ’å…¥
                price = lo + fib_ratio * g
            else:
                # æ”¯æ’‘ä½ï¼šä»é«˜å‘ä½ï¼Œåœ¨ hi - 0.618 * gap å¤„æ’å…¥
                price = hi - fib_ratio * g
            
            candidate = MTFLevelCandidate(
                price=price,
                source_fractals=[],
                source_timeframes=["filled"],
                is_resonance=False,
                merged_price=price,
            )
            candidate.score = fill_score
            candidate.fill_type = "gap_to_price"
            filled.append(candidate)
            
            # é€’å½’æ£€æŸ¥ä¸¤ä¾§
            recursive_fill(lo, price, depth + 1)
            recursive_fill(price, hi, depth + 1)
        
        recursive_fill(lower, upper)
        
        logger.debug(f"_fill_gap_to_price: åœ¨ {lower:.2f} ~ {upper:.2f} è¡¥å…¨ {len(filled)} ä¸ªæ°´ä½")
        
        return filled
    
    def _generate_fallback_resistance(
        self,
        klines_by_tf: Dict[str, List[Dict]],
        current_price: float,
        max_levels: int,
    ) -> Optional[List[Tuple[float, LevelScore]]]:
        """
        å½“æ— æ³•ä»åˆ†å½¢ç‚¹æå–é˜»åŠ›ä½æ—¶ï¼Œä½¿ç”¨å¤‡é€‰æ–¹æ¡ˆç”Ÿæˆ
        
        å¤‡é€‰ç­–ç•¥:
        1. åŸºäº ATR å‘ä¸Šæ‰©å±•å¿ƒç†ä½ (æ•´æ•°ä½ã€.500 ä½)
        2. ä½¿ç”¨æœ€è¿‘é«˜ç‚¹ + ATR åç§»
        """
        # è·å–ä¸»æ—¶é—´æ¡†æ¶ K çº¿è®¡ç®— ATR
        main_tf = self._get_main_timeframe(klines_by_tf)
        klines = klines_by_tf.get(main_tf, [])
        
        if len(klines) < 14:
            return None
        
        # è®¡ç®— ATR
        atr = self.atr_auditor._calculate_atr(klines, 14)
        if atr <= 0:
            return None
        
        # æ‰¾åˆ°æœ€è¿‘å†å²é«˜ç‚¹
        recent_high = max(float(k.get("high", 0)) for k in klines[-55:])
        
        # ç”Ÿæˆé˜»åŠ›ä½: ä½¿ç”¨å¿ƒç†ä½
        fallback_prices = []
        
        # æ–¹æ³•1: ä»å½“å‰ä»·å‘ä¸Šæ‰¾å¿ƒç†ä½
        base_price = current_price * (1 + 0.005)  # è‡³å°‘ 0.5% ä»¥ä¸Š
        
        # æ ¹æ®ä»·æ ¼é‡çº§ç¡®å®šå¿ƒç†ä½æ­¥é•¿
        if current_price >= 10000:
            step = 1000  # BTC çº§åˆ«: æ¯ $1000
        elif current_price >= 1000:
            step = 100   # ETH çº§åˆ«: æ¯ $100
        elif current_price >= 100:
            step = 10    # ä¸­ç­‰å¸‚å€¼: æ¯ $10
        else:
            step = 1     # å°å¸‚å€¼: æ¯ $1
        
        # æ‰¾ä¸‹ä¸€ä¸ªæ•´æ•°å¿ƒç†ä½
        next_round = (int(base_price / step) + 1) * step
        
        # ç”Ÿæˆä¸€ç³»åˆ—å¿ƒç†ä½
        for i in range(max_levels * 2):
            price = next_round + i * step
            
            # è·ç¦»æ£€æŸ¥
            distance_pct = (price - current_price) / current_price
            if distance_pct < self.min_distance_pct:
                continue
            if distance_pct > self.max_distance_pct:
                break
            
            fallback_prices.append(price)
            if len(fallback_prices) >= max_levels:
                break
        
        # å¦‚æœå¿ƒç†ä½ä¸å¤Ÿï¼Œè¡¥å…… ATR åŸºç¡€çš„é˜»åŠ›ä½
        if len(fallback_prices) < max_levels:
            base = recent_high if recent_high > current_price else current_price
            for i in range(1, max_levels + 1):
                price = base + i * atr * 0.5
                distance_pct = (price - current_price) / current_price
                if self.min_distance_pct <= distance_pct <= self.max_distance_pct:
                    if price not in fallback_prices:
                        fallback_prices.append(price)
                if len(fallback_prices) >= max_levels:
                    break
        
        if not fallback_prices:
            return None
        
        # ç”Ÿæˆ LevelScore (å¤‡é€‰é˜»åŠ›ä½å›ºå®šè¯„åˆ†è¾ƒä½)
        result = []
        for price in sorted(set(fallback_prices), reverse=True)[:max_levels]:
            score = LevelScore(
                base_score=35,  # å¤‡é€‰ä½åŸºç¡€åˆ†è¾ƒä½
                volume_weight=1.0,
                psychology_weight=1.2,  # å¿ƒç†ä½åŠ æˆ
                trend_coefficient=1.0,
                mtf_coefficient=1.0,
                source_timeframes=["fallback"],
                is_resonance=False,
                psychology_anchor=price,  # å¿ƒç†é”šç‚¹
            )
            result.append((price, score))
        
        # æŒ‰ä»·æ ¼é™åºæ’åˆ—
        result.sort(key=lambda x: x[0], reverse=True)
        
        logger.info(
            f"[Fallback] ç”Ÿæˆ {len(result)} ä¸ªå¤‡é€‰é˜»åŠ›ä½, "
            f"ATR={atr:.2f}, recent_high={recent_high:.2f}"
        )
        
        return result